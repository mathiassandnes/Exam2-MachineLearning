{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Problem 1: Basic Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 1. Use arange to create a NumPy array with 100 equally spaced values in the range 0\n",
    "# through 100 (not including 100). Name this NumPy array a\n",
    "\n",
    "import numpy as np\n",
    "a = np.arange(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 2. Use arange to create a NumPy array with 10 equally spaced values in the range 0\n",
    "# through 100 (not including 100). Name this NumPy array b.\n",
    "\n",
    "b = np.arange(0, 100, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 3. Create a random two-dimensional array with the dimensions 10 by 10. Call this\n",
    "# NumPy array c.\n",
    "\n",
    "c = np.random.rand(10,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#4. Reshape a so that it is a two-dimensional array with the dimensions 10 by 10.\n",
    "\n",
    "a = a.reshape(10,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "45"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Show the results of “a[4,5]” and explain the results in a comment.\n",
    "a[4,5]\n",
    "# The matrix starts with a value of 0 on the 0th index of both dimensions. There for the index will be the same as the numbers separated by a comma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "49.632830795528385"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Show the sum of c.\n",
    "\n",
    "np.sum(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Show the transpose of b.\n",
    "np.transpose(b)\n",
    "# very funny :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.82230709,  1.91364575,  2.28597371,  3.61125933,  4.58245464,\n         5.46607506,  6.38698664,  7.402321  ,  8.8065476 ,  9.28970094],\n       [10.58465506, 11.46760158, 12.85532213, 13.71997354, 14.03224251,\n        15.7590987 , 16.36733497, 17.0131417 , 18.81560248, 19.82526765],\n       [20.90532182, 21.30562391, 22.00604026, 23.2527421 , 24.52867754,\n        25.14411686, 26.39928661, 27.56017477, 28.90879304, 29.63813205],\n       [30.42830091, 31.60633312, 32.31178239, 33.08011875, 34.44505597,\n        35.28996689, 36.29285416, 37.77307294, 38.68917246, 39.8120014 ],\n       [40.77802954, 41.52957503, 42.38349186, 43.91185449, 44.30811549,\n        45.49661244, 46.25640079, 47.1421214 , 48.90774101, 49.86071153],\n       [50.91684828, 51.27733517, 52.5877166 , 53.7332151 , 54.86468654,\n        55.44144017, 56.37492588, 57.43506749, 58.27739299, 59.00820184],\n       [60.17063497, 61.14310701, 62.14960755, 63.38956515, 64.30687327,\n        65.16889982, 66.81609164, 67.07300882, 68.89763758, 69.74986718],\n       [70.11989059, 71.48631642, 72.23429768, 73.47245227, 74.69101657,\n        75.03877357, 76.43652581, 77.60476406, 78.3049237 , 79.40051663],\n       [80.74676801, 81.20707927, 82.65037461, 83.04894059, 84.97447093,\n        85.56982169, 86.99919858, 87.07220726, 88.61915644, 89.61456582],\n       [90.69056611, 91.12222144, 92.24923784, 93.78657985, 94.22509293,\n        95.61276678, 96.9529974 , 97.76374607, 98.80986628, 99.38583889]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Show the results of adding a and c\n",
    "\n",
    "a + c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.        ,  0.91364575,  0.57194743,  1.83377799,  2.32981855,\n         2.33037531,  2.32191984,  2.816247  ,  6.45238081,  2.60730843],\n       [ 5.84655063,  5.14361742, 10.26386552,  9.35965603,  0.45139507,\n        11.3864805 ,  5.87735952,  0.22340895, 14.68084457, 15.68008541],\n       [18.10643644,  6.41810208,  0.13288564,  5.81306819, 12.68826108,\n         3.60292148, 10.38145199, 15.12471868, 25.44620513, 18.50582957],\n       [12.84902742, 18.79632666,  9.97703647,  2.64391875, 15.13190306,\n        10.14884121, 10.54274967, 28.60369892, 26.18855348, 31.66805444],\n       [31.12118164, 21.71257637, 16.10665792, 39.20974321, 13.55708165,\n        22.34755995, 11.79443631,  6.67970571, 43.57156871, 42.17486503],\n       [45.84241409, 14.14409388, 30.56126308, 38.86040054, 46.69307311,\n        24.27920916, 20.99584906, 24.798847  , 16.08879358,  0.48390885],\n       [10.23809798,  8.72952781,  9.27566831, 24.54260423, 19.63988958,\n        10.97848807, 53.862048  ,  4.89159081, 61.03935521, 51.74083532],\n       [ 8.39234151, 34.52846597, 16.869433  , 34.4890157 , 51.13522648,\n         2.90801798, 33.17596181, 46.56683236, 23.78404889, 31.64081341],\n       [59.74144051, 16.77342074, 53.33071771,  4.06206872, 81.85555796,\n        48.43484405, 85.93107828,  6.2820319 , 54.48576649, 54.69635835],\n       [62.15095013, 11.12215109, 22.92988169, 73.1519261 , 21.15873556,\n        58.21284363, 91.48775059, 74.08336855, 79.36689561, 38.19805021]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Show the results of multiplying a and c\n",
    "\n",
    "a * c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 25.42884403,  13.42230891,  16.25916675,  21.8946076 ,\n         24.48061965,  17.46917214,  29.46749902,  18.31930713,\n         29.48097438,  23.71328736],\n       [ 87.06206799,  54.01069606,  53.39761298,  71.96161928,\n         74.06748364,  57.34489197,  82.29352385,  56.71556221,\n         99.84931023,  79.56132672],\n       [148.69529194,  94.59908321,  90.53605921, 122.02863097,\n        123.65434763,  97.2206118 , 135.11954868,  95.11181729,\n        170.21764608, 135.40936607],\n       [210.32851589, 135.18747036, 127.67450545, 172.09564266,\n        173.24121162, 137.09633163, 187.94557351, 133.50807237,\n        240.58598193, 191.25740543],\n       [271.96173984, 175.77585751, 164.81295168, 222.16265435,\n        222.82807561, 176.97205146, 240.77159834, 171.90432745,\n        310.95431778, 247.10544478],\n       [333.59496379, 216.36424466, 201.95139791, 272.22966604,\n        272.4149396 , 216.84777129, 293.59762317, 210.30058253,\n        381.32265363, 302.95348414],\n       [395.22818774, 256.95263181, 239.08984414, 322.29667773,\n        322.00180359, 256.72349111, 346.42364801, 248.69683761,\n        451.69098948, 358.80152349],\n       [456.86141169, 297.54101895, 276.22829037, 372.36368942,\n        371.58866758, 296.59921094, 399.24967284, 287.09309269,\n        522.05932533, 414.64956285],\n       [518.49463564, 338.1294061 , 313.3667366 , 422.4307011 ,\n        421.17553157, 336.47493077, 452.07569767, 325.48934777,\n        592.42766118, 470.4976022 ],\n       [580.12785959, 378.71779325, 350.50518283, 472.49771279,\n        470.76239556, 376.3506506 , 504.9017225 , 363.88560285,\n        662.79599704, 526.34564156]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Show the results of computing the dot product of a and c.\n",
    "\n",
    "np.dot(a, c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem 2: Conceptual Questions\n",
    "\n",
    "1. What are some causes of overfitting? How do we diagnose and treat overfitting in\n",
    "regression models?\n",
    "\n",
    "    Overfitting can be caused by many things.\n",
    "    Concretely the model remembers the training data instead of learning it.\n",
    "    One cause is that the model is to complex, which means that it has to many features.\n",
    "    Another cause is that the training data does not represent the test data.\n",
    "\n",
    "    A way to evaluate a model is to divide its data intro two categories, test and train.\n",
    "    Train data is used during training.\n",
    "    Hopefully the model learns the pattern of this data.\n",
    "    We use the test data to evaluate the model after training.\n",
    "    This can lets us know if the whether the model has memorized or learned the data.\n",
    "    Its essential that the model has not seen the test data, as this defeats the purpose of it.\n",
    "\n",
    "    Overfitting can be diagnosed by comparing test and train results.\n",
    "    If the model does substantially better on the train data, its overfitting.\n",
    "\n",
    "    A way of treating overfitting in regression models is to use regularization.\n",
    "    Regularization adds the weights of the model to the loss/error, and multiplies it by a hyperparameter.\n",
    "    Regularization ensures that the weights dont get converge to high values.\n",
    "    Another way of treating overfitting is to reduce the models complexity and\n",
    "    making sure that the train data represents the test data in a good way. Another way is to reduce model complexity\n",
    "\n",
    "\n",
    "2. What are the advantages and disadvantages of using ridge regression and lasso\n",
    "regression? How are these regressions different?\n",
    "\n",
    "    Both ridge and lasso regression adds a multiple (lambda) of the weights of a model to the cost/error function.\n",
    "\n",
    "    Advantages of using these is that the model will be able to give better predictions, and reduce the chance of overfitting.\n",
    "    If we let the weights take any value they \"would like\", we can end up in a situation like this,\n",
    "    where the model is doing well on the training data, but does not generalize.\n",
    "    <img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2F6%2F68%2FOverfitted_Data.png%2F300px-Overfitted_Data.png&f=1&nofb=1\">\n",
    "\n",
    "    A disadvantage of using these is that they introduce bias, in exchange of variance.\n",
    "    They also add an extra hyper-parameter that needs to be tuned.\n",
    "\n",
    "    The only difference between ridge and lasso regression is that ridge adds the square of the weights,\n",
    "    while lasso adds the absolute value. This gives them different properties.\n",
    "\n",
    "    Lasso regression allows a model to do feature selection.\n",
    "    Let's say we want to predict how fast a car can drive.\n",
    "    There are three known values for each car: horsepower, weight and color.\n",
    "    Lasso regression would allow the model to negate the value of color, since its not important.\n",
    "\n",
    "    Since ridge regression uses the squares of the weights, it focuses more on keeping their value low."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem 3: Machine Learning Regression Problem\n",
    "The data in the file housedata.csv are collected from 1,000 homes being sold in Oslo. The\n",
    "response variable of interest is the Price (price of the house). The input variables are\n",
    "bedrooms, sqft_living (the living space area), sqft_lot (the area of the land the house sits on),\n",
    "floors (the number of levels of the house), sqft_above (area of the house excluding the\n",
    "basement), sqft_basement (basement area)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# 1. Use Multilinear Regression (MLR) and Decision Tree Regressor to build a regression\n",
    "# model for prediction of house prices?\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, tree, preprocessing\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df = pd.read_csv('C:/Users/mathi/Desktop/MLExam/housedata.csv', sep=';')\n",
    "\n",
    "y = df['price']\n",
    "X = df[['bedrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_above', 'sqft_basement']]\n",
    "\n",
    "# normalizes\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(x_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "class CustomModel:\n",
    "    def __init__(this, model, type, identifier):\n",
    "        this.model = model\n",
    "        this.type = type\n",
    "        this.identifier = identifier\n",
    "        this.predictions = None\n",
    "        this.r2 = None\n",
    "        this.mse = None\n",
    "\n",
    "    def fit(this,x ,y):\n",
    "        this.model = this.model.fit(x, y)\n",
    "\n",
    "    def predict(this, x, y):\n",
    "        this.predictions = this.model.predict(x)\n",
    "        this.r2 = r2_score(y, this.predictions)\n",
    "        this.mse = mean_squared_error(y, this.predictions)\n",
    "\n",
    "    def print_results(this):\n",
    "        print('Type: %s' % this.type)\n",
    "        print('Identifier: %s' % this.identifier)\n",
    "        print('r2: %s'% this.r2)\n",
    "        print('mse: %s \\n'% this.mse)\n",
    "\n",
    "# adds linear models to models list\n",
    "models = [\n",
    "    CustomModel(linear_model.LinearRegression(), 'MLR', 'Linear Regression'),\n",
    "    CustomModel(linear_model.Lasso(), 'MLR', 'Lasso Regression'),\n",
    "    CustomModel(linear_model.Ridge(), 'MLR', 'Ridge Regression'),\n",
    "    CustomModel(linear_model.ElasticNet(), 'MLR', 'Elastic Net Regression')\n",
    "]\n",
    "\n",
    "# adds decision tree variants to model list\n",
    "criterions = ['mse', 'friedman_mse', 'mae']\n",
    "splitters = ['best', 'random']\n",
    "# Using list comprehension would be faster, but less readable\n",
    "for c in criterions:\n",
    "    for s in splitters:\n",
    "        model = tree.DecisionTreeRegressor(criterion=c, splitter=s)\n",
    "        customModel = CustomModel(model, 'DTR', 'criterion=%s, splitter=%s' % (c, s))\n",
    "        models.append(customModel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Perform Model Evaluation using two metrics: Root Mean Squared Error and\n",
    "Coefficient of Determination? Which of the two regression models is better MLR or\n",
    "Decision Tree?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: MLR\n",
      "Identifier: Ridge Regression\n",
      "r2: 0.5210650053815418\n",
      "mse: 45708543376.80272 \n",
      "\n",
      "Type: MLR\n",
      "Identifier: Lasso Regression\n",
      "r2: 0.5188573968065748\n",
      "mse: 45919232872.12402 \n",
      "\n",
      "Type: MLR\n",
      "Identifier: Linear Regression\n",
      "r2: 0.5188511355885879\n",
      "mse: 45919830429.53195 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=mae, splitter=best\n",
      "r2: 0.20951020015508026\n",
      "mse: 75442675334.084 \n",
      "\n",
      "Type: MLR\n",
      "Identifier: Elastic Net Regression\n",
      "r2: 0.10694749470542264\n",
      "mse: 85231043115.85902 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=friedman_mse, splitter=best\n",
      "r2: 0.08589543782126918\n",
      "mse: 87240206919.032 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=mae, splitter=random\n",
      "r2: 0.08044692244675145\n",
      "mse: 87760201707.748 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=mse, splitter=best\n",
      "r2: -0.04808551123419136\n",
      "mse: 100027065449.688 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=mse, splitter=random\n",
      "r2: -0.06735869880242906\n",
      "mse: 101866457726.032 \n",
      "\n",
      "Type: DTR\n",
      "Identifier: criterion=friedman_mse, splitter=random\n",
      "r2: -0.15877293520433855\n",
      "mse: 110590839190.708 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    model.predict(X_test, y_test)\n",
    "\n",
    "models.sort(key=lambda m: m.r2, reverse=True)\n",
    "\n",
    "for model in models:\n",
    "    model.print_results()\n",
    "\n",
    "# MLR is the better model for this problem. Ridge regression does slightly better on this exact test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Problem 4: Deep Learning Problem Using Keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n0           FDA15         9.30          Low Fat         0.016047   \n1           DRC01         5.92          Regular         0.019278   \n2           FDN15        17.50          Low Fat         0.016760   \n3           FDX07        19.20          Regular         0.000000   \n4           NCD19         8.93          Low Fat         0.000000   \n\n               Item_Type  Item_MRP Outlet_Identifier  \\\n0                  Dairy  249.8092            OUT049   \n1            Soft Drinks   48.2692            OUT018   \n2                   Meat  141.6180            OUT049   \n3  Fruits and Vegetables  182.0950            OUT010   \n4              Household   53.8614            OUT013   \n\n   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n0                       1999      Medium               Tier 1   \n1                       2009      Medium               Tier 3   \n2                       1999      Medium               Tier 1   \n3                       1998         NaN               Tier 3   \n4                       1987        High               Tier 3   \n\n         Outlet_Type  Item_Outlet_Sales  \n0  Supermarket Type1          3735.1380  \n1  Supermarket Type2           443.4228  \n2  Supermarket Type1          2097.2700  \n3      Grocery Store           732.3800  \n4  Supermarket Type1           994.7052  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_Identifier</th>\n      <th>Item_Weight</th>\n      <th>Item_Fat_Content</th>\n      <th>Item_Visibility</th>\n      <th>Item_Type</th>\n      <th>Item_MRP</th>\n      <th>Outlet_Identifier</th>\n      <th>Outlet_Establishment_Year</th>\n      <th>Outlet_Size</th>\n      <th>Outlet_Location_Type</th>\n      <th>Outlet_Type</th>\n      <th>Item_Outlet_Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FDA15</td>\n      <td>9.30</td>\n      <td>Low Fat</td>\n      <td>0.016047</td>\n      <td>Dairy</td>\n      <td>249.8092</td>\n      <td>OUT049</td>\n      <td>1999</td>\n      <td>Medium</td>\n      <td>Tier 1</td>\n      <td>Supermarket Type1</td>\n      <td>3735.1380</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DRC01</td>\n      <td>5.92</td>\n      <td>Regular</td>\n      <td>0.019278</td>\n      <td>Soft Drinks</td>\n      <td>48.2692</td>\n      <td>OUT018</td>\n      <td>2009</td>\n      <td>Medium</td>\n      <td>Tier 3</td>\n      <td>Supermarket Type2</td>\n      <td>443.4228</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FDN15</td>\n      <td>17.50</td>\n      <td>Low Fat</td>\n      <td>0.016760</td>\n      <td>Meat</td>\n      <td>141.6180</td>\n      <td>OUT049</td>\n      <td>1999</td>\n      <td>Medium</td>\n      <td>Tier 1</td>\n      <td>Supermarket Type1</td>\n      <td>2097.2700</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FDX07</td>\n      <td>19.20</td>\n      <td>Regular</td>\n      <td>0.000000</td>\n      <td>Fruits and Vegetables</td>\n      <td>182.0950</td>\n      <td>OUT010</td>\n      <td>1998</td>\n      <td>NaN</td>\n      <td>Tier 3</td>\n      <td>Grocery Store</td>\n      <td>732.3800</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NCD19</td>\n      <td>8.93</td>\n      <td>Low Fat</td>\n      <td>0.000000</td>\n      <td>Household</td>\n      <td>53.8614</td>\n      <td>OUT013</td>\n      <td>1987</td>\n      <td>High</td>\n      <td>Tier 3</td>\n      <td>Supermarket Type1</td>\n      <td>994.7052</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b5b5e5c6",
   "language": "python",
   "display_name": "PyCharm (MLExam)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}